{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 876,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03424657534246575,
      "grad_norm": 0.32458963990211487,
      "learning_rate": 7.258064516129033e-07,
      "loss": 0.0345,
      "step": 10
    },
    {
      "epoch": 0.0684931506849315,
      "grad_norm": 0.3352462947368622,
      "learning_rate": 1.5322580645161292e-06,
      "loss": 0.0164,
      "step": 20
    },
    {
      "epoch": 0.10273972602739725,
      "grad_norm": 0.36451825499534607,
      "learning_rate": 2.338709677419355e-06,
      "loss": 0.038,
      "step": 30
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 0.30779263377189636,
      "learning_rate": 3.145161290322581e-06,
      "loss": 0.0278,
      "step": 40
    },
    {
      "epoch": 0.17123287671232876,
      "grad_norm": 0.12766233086585999,
      "learning_rate": 3.951612903225807e-06,
      "loss": 0.0287,
      "step": 50
    },
    {
      "epoch": 0.2054794520547945,
      "grad_norm": 0.08368513733148575,
      "learning_rate": 4.758064516129033e-06,
      "loss": 0.0217,
      "step": 60
    },
    {
      "epoch": 0.23972602739726026,
      "grad_norm": 0.3258029818534851,
      "learning_rate": 4.999846115781729e-06,
      "loss": 0.0174,
      "step": 70
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 0.24710652232170105,
      "learning_rate": 4.99909244276641e-06,
      "loss": 0.0214,
      "step": 80
    },
    {
      "epoch": 0.3082191780821918,
      "grad_norm": 0.1636500507593155,
      "learning_rate": 4.997710905619523e-06,
      "loss": 0.0165,
      "step": 90
    },
    {
      "epoch": 0.3424657534246575,
      "grad_norm": 0.3367480933666229,
      "learning_rate": 4.995701851434118e-06,
      "loss": 0.0302,
      "step": 100
    },
    {
      "epoch": 0.3767123287671233,
      "grad_norm": 0.271185040473938,
      "learning_rate": 4.993065784958655e-06,
      "loss": 0.0456,
      "step": 110
    },
    {
      "epoch": 0.410958904109589,
      "grad_norm": 0.33894261717796326,
      "learning_rate": 4.98980336847019e-06,
      "loss": 0.0284,
      "step": 120
    },
    {
      "epoch": 0.4452054794520548,
      "grad_norm": 0.49479591846466064,
      "learning_rate": 4.985915421607991e-06,
      "loss": 0.0273,
      "step": 130
    },
    {
      "epoch": 0.4794520547945205,
      "grad_norm": 0.09848782420158386,
      "learning_rate": 4.981402921167608e-06,
      "loss": 0.031,
      "step": 140
    },
    {
      "epoch": 0.5136986301369864,
      "grad_norm": 0.17552176117897034,
      "learning_rate": 4.976267000855469e-06,
      "loss": 0.027,
      "step": 150
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 0.2756041884422302,
      "learning_rate": 4.970508951004056e-06,
      "loss": 0.0304,
      "step": 160
    },
    {
      "epoch": 0.5821917808219178,
      "grad_norm": 0.05108048394322395,
      "learning_rate": 4.964130218247715e-06,
      "loss": 0.0296,
      "step": 170
    },
    {
      "epoch": 0.6164383561643836,
      "grad_norm": 0.46411895751953125,
      "learning_rate": 4.957132405159222e-06,
      "loss": 0.0392,
      "step": 180
    },
    {
      "epoch": 0.6506849315068494,
      "grad_norm": 0.19455543160438538,
      "learning_rate": 4.949517269847141e-06,
      "loss": 0.0146,
      "step": 190
    },
    {
      "epoch": 0.684931506849315,
      "grad_norm": 0.08436702936887741,
      "learning_rate": 4.9412867255141385e-06,
      "loss": 0.0189,
      "step": 200
    },
    {
      "epoch": 0.7191780821917808,
      "grad_norm": 0.2268954962491989,
      "learning_rate": 4.932442839976307e-06,
      "loss": 0.0139,
      "step": 210
    },
    {
      "epoch": 0.7534246575342466,
      "grad_norm": 0.4096520245075226,
      "learning_rate": 4.922987835143655e-06,
      "loss": 0.0251,
      "step": 220
    },
    {
      "epoch": 0.7876712328767124,
      "grad_norm": 0.19776517152786255,
      "learning_rate": 4.912924086461884e-06,
      "loss": 0.021,
      "step": 230
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 0.34356358647346497,
      "learning_rate": 4.9022541223155866e-06,
      "loss": 0.0262,
      "step": 240
    },
    {
      "epoch": 0.8561643835616438,
      "grad_norm": 0.66025310754776,
      "learning_rate": 4.890980623393021e-06,
      "loss": 0.0301,
      "step": 250
    },
    {
      "epoch": 0.8904109589041096,
      "grad_norm": 0.04222177341580391,
      "learning_rate": 4.879106422012629e-06,
      "loss": 0.0241,
      "step": 260
    },
    {
      "epoch": 0.9246575342465754,
      "grad_norm": 0.33756157755851746,
      "learning_rate": 4.8666345014114495e-06,
      "loss": 0.0436,
      "step": 270
    },
    {
      "epoch": 0.958904109589041,
      "grad_norm": 0.5391907691955566,
      "learning_rate": 4.853567994995618e-06,
      "loss": 0.0321,
      "step": 280
    },
    {
      "epoch": 0.9931506849315068,
      "grad_norm": 0.4055587351322174,
      "learning_rate": 4.839910185553145e-06,
      "loss": 0.0256,
      "step": 290
    },
    {
      "epoch": 1.0273972602739727,
      "grad_norm": 0.2560183107852936,
      "learning_rate": 4.825664504429153e-06,
      "loss": 0.0332,
      "step": 300
    },
    {
      "epoch": 1.0616438356164384,
      "grad_norm": 0.28145402669906616,
      "learning_rate": 4.810834530663797e-06,
      "loss": 0.023,
      "step": 310
    },
    {
      "epoch": 1.095890410958904,
      "grad_norm": 0.17729079723358154,
      "learning_rate": 4.795423990093082e-06,
      "loss": 0.0239,
      "step": 320
    },
    {
      "epoch": 1.13013698630137,
      "grad_norm": 0.2611127495765686,
      "learning_rate": 4.779436754412791e-06,
      "loss": 0.013,
      "step": 330
    },
    {
      "epoch": 1.1643835616438356,
      "grad_norm": 0.20872920751571655,
      "learning_rate": 4.762876840205773e-06,
      "loss": 0.0119,
      "step": 340
    },
    {
      "epoch": 1.1986301369863013,
      "grad_norm": 0.19450898468494415,
      "learning_rate": 4.745748407932832e-06,
      "loss": 0.0234,
      "step": 350
    },
    {
      "epoch": 1.2328767123287672,
      "grad_norm": 0.2972724735736847,
      "learning_rate": 4.7280557608874645e-06,
      "loss": 0.025,
      "step": 360
    },
    {
      "epoch": 1.2671232876712328,
      "grad_norm": 0.10254504531621933,
      "learning_rate": 4.7098033441147125e-06,
      "loss": 0.0183,
      "step": 370
    },
    {
      "epoch": 1.3013698630136985,
      "grad_norm": 0.12499736994504929,
      "learning_rate": 4.690995743294404e-06,
      "loss": 0.0181,
      "step": 380
    },
    {
      "epoch": 1.3356164383561644,
      "grad_norm": 0.6015827655792236,
      "learning_rate": 4.6716376835890656e-06,
      "loss": 0.021,
      "step": 390
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 0.2919952869415283,
      "learning_rate": 4.6517340284567795e-06,
      "loss": 0.0185,
      "step": 400
    },
    {
      "epoch": 1.404109589041096,
      "grad_norm": 0.1826498955488205,
      "learning_rate": 4.6312897784293136e-06,
      "loss": 0.0278,
      "step": 410
    },
    {
      "epoch": 1.4383561643835616,
      "grad_norm": 0.3195760250091553,
      "learning_rate": 4.6103100698557935e-06,
      "loss": 0.0282,
      "step": 420
    },
    {
      "epoch": 1.4726027397260273,
      "grad_norm": 0.0036555675324052572,
      "learning_rate": 4.5888001736122715e-06,
      "loss": 0.0132,
      "step": 430
    },
    {
      "epoch": 1.5068493150684932,
      "grad_norm": 0.3320177495479584,
      "learning_rate": 4.5667654937774815e-06,
      "loss": 0.0222,
      "step": 440
    },
    {
      "epoch": 1.541095890410959,
      "grad_norm": 0.10509506613016129,
      "learning_rate": 4.544211566275138e-06,
      "loss": 0.0115,
      "step": 450
    },
    {
      "epoch": 1.5753424657534247,
      "grad_norm": 0.6430231332778931,
      "learning_rate": 4.521144057483107e-06,
      "loss": 0.0313,
      "step": 460
    },
    {
      "epoch": 1.6095890410958904,
      "grad_norm": 0.28408828377723694,
      "learning_rate": 4.497568762809805e-06,
      "loss": 0.02,
      "step": 470
    },
    {
      "epoch": 1.643835616438356,
      "grad_norm": 0.4058386981487274,
      "learning_rate": 4.473491605238178e-06,
      "loss": 0.0192,
      "step": 480
    },
    {
      "epoch": 1.678082191780822,
      "grad_norm": 0.027567604556679726,
      "learning_rate": 4.448918633837626e-06,
      "loss": 0.0188,
      "step": 490
    },
    {
      "epoch": 1.7123287671232876,
      "grad_norm": 0.1403457373380661,
      "learning_rate": 4.4238560222442615e-06,
      "loss": 0.0257,
      "step": 500
    },
    {
      "epoch": 1.7465753424657535,
      "grad_norm": 0.24522821605205536,
      "learning_rate": 4.3983100671098586e-06,
      "loss": 0.0228,
      "step": 510
    },
    {
      "epoch": 1.7808219178082192,
      "grad_norm": 0.15995745360851288,
      "learning_rate": 4.372287186519903e-06,
      "loss": 0.0097,
      "step": 520
    },
    {
      "epoch": 1.8150684931506849,
      "grad_norm": 0.3117015063762665,
      "learning_rate": 4.345793918381134e-06,
      "loss": 0.0199,
      "step": 530
    },
    {
      "epoch": 1.8493150684931505,
      "grad_norm": 0.21654903888702393,
      "learning_rate": 4.3188369187789784e-06,
      "loss": 0.0136,
      "step": 540
    },
    {
      "epoch": 1.8835616438356164,
      "grad_norm": 0.209788516163826,
      "learning_rate": 4.2914229603053016e-06,
      "loss": 0.0167,
      "step": 550
    },
    {
      "epoch": 1.9178082191780823,
      "grad_norm": 0.32458916306495667,
      "learning_rate": 4.263558930356877e-06,
      "loss": 0.015,
      "step": 560
    },
    {
      "epoch": 1.952054794520548,
      "grad_norm": 0.012419109232723713,
      "learning_rate": 4.235251829405024e-06,
      "loss": 0.0164,
      "step": 570
    },
    {
      "epoch": 1.9863013698630136,
      "grad_norm": 0.3361894488334656,
      "learning_rate": 4.2065087692368256e-06,
      "loss": 0.0212,
      "step": 580
    },
    {
      "epoch": 2.0205479452054793,
      "grad_norm": 0.09797172248363495,
      "learning_rate": 4.177336971168389e-06,
      "loss": 0.0221,
      "step": 590
    },
    {
      "epoch": 2.0547945205479454,
      "grad_norm": 0.12627959251403809,
      "learning_rate": 4.147743764230585e-06,
      "loss": 0.0103,
      "step": 600
    },
    {
      "epoch": 2.089041095890411,
      "grad_norm": 0.03036600723862648,
      "learning_rate": 4.117736583327724e-06,
      "loss": 0.0144,
      "step": 610
    },
    {
      "epoch": 2.1232876712328768,
      "grad_norm": 0.16756586730480194,
      "learning_rate": 4.087322967369632e-06,
      "loss": 0.0107,
      "step": 620
    },
    {
      "epoch": 2.1575342465753424,
      "grad_norm": 0.04343920946121216,
      "learning_rate": 4.056510557377607e-06,
      "loss": 0.0083,
      "step": 630
    },
    {
      "epoch": 2.191780821917808,
      "grad_norm": 0.14098525047302246,
      "learning_rate": 4.025307094564701e-06,
      "loss": 0.0123,
      "step": 640
    },
    {
      "epoch": 2.2260273972602738,
      "grad_norm": 1.3622153997421265,
      "learning_rate": 3.993720418390849e-06,
      "loss": 0.0181,
      "step": 650
    },
    {
      "epoch": 2.26027397260274,
      "grad_norm": 0.17122530937194824,
      "learning_rate": 3.9617584645933085e-06,
      "loss": 0.0061,
      "step": 660
    },
    {
      "epoch": 2.2945205479452055,
      "grad_norm": 0.41828757524490356,
      "learning_rate": 3.929429263192906e-06,
      "loss": 0.0176,
      "step": 670
    },
    {
      "epoch": 2.328767123287671,
      "grad_norm": 0.6638104319572449,
      "learning_rate": 3.896740936476603e-06,
      "loss": 0.0181,
      "step": 680
    },
    {
      "epoch": 2.363013698630137,
      "grad_norm": 0.0020079289097338915,
      "learning_rate": 3.8637016969568755e-06,
      "loss": 0.0123,
      "step": 690
    },
    {
      "epoch": 2.3972602739726026,
      "grad_norm": 0.7076249718666077,
      "learning_rate": 3.83031984530843e-06,
      "loss": 0.0384,
      "step": 700
    },
    {
      "epoch": 2.4315068493150687,
      "grad_norm": 0.34688282012939453,
      "learning_rate": 3.7966037682827683e-06,
      "loss": 0.0315,
      "step": 710
    },
    {
      "epoch": 2.4657534246575343,
      "grad_norm": 0.33905357122421265,
      "learning_rate": 3.7625619366011234e-06,
      "loss": 0.0103,
      "step": 720
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.38411280512809753,
      "learning_rate": 3.7282029028263064e-06,
      "loss": 0.0172,
      "step": 730
    },
    {
      "epoch": 2.5342465753424657,
      "grad_norm": 0.18945571780204773,
      "learning_rate": 3.6935352992139844e-06,
      "loss": 0.0031,
      "step": 740
    },
    {
      "epoch": 2.5684931506849313,
      "grad_norm": 0.5222576260566711,
      "learning_rate": 3.658567835543942e-06,
      "loss": 0.0204,
      "step": 750
    },
    {
      "epoch": 2.602739726027397,
      "grad_norm": 0.07659266144037247,
      "learning_rate": 3.6233092969318607e-06,
      "loss": 0.0184,
      "step": 760
    },
    {
      "epoch": 2.636986301369863,
      "grad_norm": 0.20666532218456268,
      "learning_rate": 3.5877685416221757e-06,
      "loss": 0.0138,
      "step": 770
    },
    {
      "epoch": 2.671232876712329,
      "grad_norm": 0.3397608995437622,
      "learning_rate": 3.551954498762561e-06,
      "loss": 0.0105,
      "step": 780
    },
    {
      "epoch": 2.7054794520547945,
      "grad_norm": 0.1760360449552536,
      "learning_rate": 3.5158761661605934e-06,
      "loss": 0.0157,
      "step": 790
    },
    {
      "epoch": 2.73972602739726,
      "grad_norm": 0.05608443170785904,
      "learning_rate": 3.479542608023173e-06,
      "loss": 0.0047,
      "step": 800
    },
    {
      "epoch": 2.7739726027397262,
      "grad_norm": 0.5246906280517578,
      "learning_rate": 3.442962952679265e-06,
      "loss": 0.0161,
      "step": 810
    },
    {
      "epoch": 2.808219178082192,
      "grad_norm": 0.11456641554832458,
      "learning_rate": 3.40614639028652e-06,
      "loss": 0.016,
      "step": 820
    },
    {
      "epoch": 2.8424657534246576,
      "grad_norm": 0.374604731798172,
      "learning_rate": 3.3691021705223725e-06,
      "loss": 0.0134,
      "step": 830
    },
    {
      "epoch": 2.8767123287671232,
      "grad_norm": 0.011252794414758682,
      "learning_rate": 3.3318396002601794e-06,
      "loss": 0.0043,
      "step": 840
    },
    {
      "epoch": 2.910958904109589,
      "grad_norm": 0.034399084746837616,
      "learning_rate": 3.2943680412309907e-06,
      "loss": 0.0063,
      "step": 850
    },
    {
      "epoch": 2.9452054794520546,
      "grad_norm": 0.3940301537513733,
      "learning_rate": 3.256696907671538e-06,
      "loss": 0.0186,
      "step": 860
    },
    {
      "epoch": 2.9794520547945207,
      "grad_norm": 0.009146841242909431,
      "learning_rate": 3.218835663959028e-06,
      "loss": 0.018,
      "step": 870
    }
  ],
  "logging_steps": 10,
  "max_steps": 2044,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.271414875382661e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
