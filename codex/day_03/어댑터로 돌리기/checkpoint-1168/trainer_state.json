{
  "best_global_step": 292,
  "best_metric": 0.01156033668667078,
  "best_model_checkpoint": "/home/team102/workspace/runs/qwen25vl_lora/checkpoint-292",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1168,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03424657534246575,
      "grad_norm": 0.4002456068992615,
      "learning_rate": 1.8493150684931507e-06,
      "loss": 0.0375,
      "step": 10
    },
    {
      "epoch": 0.0684931506849315,
      "grad_norm": 0.2254789173603058,
      "learning_rate": 3.904109589041096e-06,
      "loss": 0.0166,
      "step": 20
    },
    {
      "epoch": 0.10273972602739725,
      "grad_norm": 0.3868204355239868,
      "learning_rate": 5.958904109589041e-06,
      "loss": 0.0338,
      "step": 30
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 0.04241539165377617,
      "learning_rate": 8.013698630136987e-06,
      "loss": 0.0277,
      "step": 40
    },
    {
      "epoch": 0.17123287671232876,
      "grad_norm": 0.26856163144111633,
      "learning_rate": 1.0068493150684931e-05,
      "loss": 0.0232,
      "step": 50
    },
    {
      "epoch": 0.2054794520547945,
      "grad_norm": 0.20079511404037476,
      "learning_rate": 1.2123287671232878e-05,
      "loss": 0.0273,
      "step": 60
    },
    {
      "epoch": 0.23972602739726026,
      "grad_norm": 0.3551782965660095,
      "learning_rate": 1.4178082191780822e-05,
      "loss": 0.0279,
      "step": 70
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 0.3912070691585541,
      "learning_rate": 1.4999307413682568e-05,
      "loss": 0.0236,
      "step": 80
    },
    {
      "epoch": 0.3082191780821918,
      "grad_norm": 0.6314306855201721,
      "learning_rate": 1.4995075404959857e-05,
      "loss": 0.0361,
      "step": 90
    },
    {
      "epoch": 0.3424657534246575,
      "grad_norm": 0.31451523303985596,
      "learning_rate": 1.498699832613368e-05,
      "loss": 0.0229,
      "step": 100
    },
    {
      "epoch": 0.3767123287671233,
      "grad_norm": 0.618735671043396,
      "learning_rate": 1.4975080320849377e-05,
      "loss": 0.0289,
      "step": 110
    },
    {
      "epoch": 0.410958904109589,
      "grad_norm": 0.04003865271806717,
      "learning_rate": 1.495932750319699e-05,
      "loss": 0.0172,
      "step": 120
    },
    {
      "epoch": 0.4452054794520548,
      "grad_norm": 0.12031620740890503,
      "learning_rate": 1.4939747954574616e-05,
      "loss": 0.0182,
      "step": 130
    },
    {
      "epoch": 0.4794520547945205,
      "grad_norm": 0.20369327068328857,
      "learning_rate": 1.4916351719542587e-05,
      "loss": 0.0305,
      "step": 140
    },
    {
      "epoch": 0.5136986301369864,
      "grad_norm": 0.5011608600616455,
      "learning_rate": 1.4889150800670454e-05,
      "loss": 0.0254,
      "step": 150
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 0.15161572396755219,
      "learning_rate": 1.4858159152379529e-05,
      "loss": 0.0216,
      "step": 160
    },
    {
      "epoch": 0.5821917808219178,
      "grad_norm": 0.6225349307060242,
      "learning_rate": 1.4823392673784072e-05,
      "loss": 0.043,
      "step": 170
    },
    {
      "epoch": 0.6164383561643836,
      "grad_norm": 0.35605016350746155,
      "learning_rate": 1.4784869200534864e-05,
      "loss": 0.0156,
      "step": 180
    },
    {
      "epoch": 0.6506849315068494,
      "grad_norm": 0.3048365116119385,
      "learning_rate": 1.4742608495669265e-05,
      "loss": 0.0358,
      "step": 190
    },
    {
      "epoch": 0.684931506849315,
      "grad_norm": 0.5315867066383362,
      "learning_rate": 1.4696632239472537e-05,
      "loss": 0.0224,
      "step": 200
    },
    {
      "epoch": 0.7191780821917808,
      "grad_norm": 0.37705913186073303,
      "learning_rate": 1.464696401835557e-05,
      "loss": 0.0211,
      "step": 210
    },
    {
      "epoch": 0.7534246575342466,
      "grad_norm": 0.25763535499572754,
      "learning_rate": 1.4593629312754759e-05,
      "loss": 0.0211,
      "step": 220
    },
    {
      "epoch": 0.7876712328767124,
      "grad_norm": 0.27029815316200256,
      "learning_rate": 1.4536655484060205e-05,
      "loss": 0.0261,
      "step": 230
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 0.48143255710601807,
      "learning_rate": 1.4476071760578967e-05,
      "loss": 0.027,
      "step": 240
    },
    {
      "epoch": 0.8561643835616438,
      "grad_norm": 0.2267788201570511,
      "learning_rate": 1.4411909222540576e-05,
      "loss": 0.0112,
      "step": 250
    },
    {
      "epoch": 0.8904109589041096,
      "grad_norm": 0.04646068811416626,
      "learning_rate": 1.4344200786152463e-05,
      "loss": 0.0339,
      "step": 260
    },
    {
      "epoch": 0.9246575342465754,
      "grad_norm": 0.29707032442092896,
      "learning_rate": 1.427298118671354e-05,
      "loss": 0.0261,
      "step": 270
    },
    {
      "epoch": 0.958904109589041,
      "grad_norm": 0.6008582711219788,
      "learning_rate": 1.419828696079452e-05,
      "loss": 0.0232,
      "step": 280
    },
    {
      "epoch": 0.9931506849315068,
      "grad_norm": 0.04170532524585724,
      "learning_rate": 1.4120156427494212e-05,
      "loss": 0.0218,
      "step": 290
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.01156033668667078,
      "eval_runtime": 37.9973,
      "eval_samples_per_second": 3.369,
      "eval_steps_per_second": 0.421,
      "step": 292
    },
    {
      "epoch": 1.0273972602739727,
      "grad_norm": 0.033414095640182495,
      "learning_rate": 1.4038629668781308e-05,
      "loss": 0.0104,
      "step": 300
    },
    {
      "epoch": 1.0616438356164384,
      "grad_norm": 0.05667343735694885,
      "learning_rate": 1.3953748508931835e-05,
      "loss": 0.0093,
      "step": 310
    },
    {
      "epoch": 1.095890410958904,
      "grad_norm": 0.08446081727743149,
      "learning_rate": 1.3865556493072752e-05,
      "loss": 0.0094,
      "step": 320
    },
    {
      "epoch": 1.13013698630137,
      "grad_norm": 0.298246830701828,
      "learning_rate": 1.3774098864842745e-05,
      "loss": 0.0129,
      "step": 330
    },
    {
      "epoch": 1.1643835616438356,
      "grad_norm": 0.5611376166343689,
      "learning_rate": 1.3679422543181656e-05,
      "loss": 0.0182,
      "step": 340
    },
    {
      "epoch": 1.1986301369863013,
      "grad_norm": 0.016240432858467102,
      "learning_rate": 1.3581576098260469e-05,
      "loss": 0.0155,
      "step": 350
    },
    {
      "epoch": 1.2328767123287672,
      "grad_norm": 0.19467121362686157,
      "learning_rate": 1.3480609726564173e-05,
      "loss": 0.0144,
      "step": 360
    },
    {
      "epoch": 1.2671232876712328,
      "grad_norm": 0.022898882627487183,
      "learning_rate": 1.3376575225140336e-05,
      "loss": 0.0041,
      "step": 370
    },
    {
      "epoch": 1.3013698630136985,
      "grad_norm": 0.37721142172813416,
      "learning_rate": 1.3269525965026547e-05,
      "loss": 0.0126,
      "step": 380
    },
    {
      "epoch": 1.3356164383561644,
      "grad_norm": 0.12922848761081696,
      "learning_rate": 1.315951686387038e-05,
      "loss": 0.0116,
      "step": 390
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 0.07670458406209946,
      "learning_rate": 1.3046604357755948e-05,
      "loss": 0.0082,
      "step": 400
    },
    {
      "epoch": 1.404109589041096,
      "grad_norm": 0.005120288114994764,
      "learning_rate": 1.2930846372251455e-05,
      "loss": 0.0039,
      "step": 410
    },
    {
      "epoch": 1.4383561643835616,
      "grad_norm": 0.025996584445238113,
      "learning_rate": 1.2812302292692641e-05,
      "loss": 0.0084,
      "step": 420
    },
    {
      "epoch": 1.4726027397260273,
      "grad_norm": 0.039750270545482635,
      "learning_rate": 1.2691032933717332e-05,
      "loss": 0.0077,
      "step": 430
    },
    {
      "epoch": 1.5068493150684932,
      "grad_norm": 0.9912045001983643,
      "learning_rate": 1.2567100508066754e-05,
      "loss": 0.0137,
      "step": 440
    },
    {
      "epoch": 1.541095890410959,
      "grad_norm": 0.0007480239728465676,
      "learning_rate": 1.2440568594669608e-05,
      "loss": 0.0052,
      "step": 450
    },
    {
      "epoch": 1.5753424657534247,
      "grad_norm": 0.002921855077147484,
      "learning_rate": 1.2311502106025234e-05,
      "loss": 0.0198,
      "step": 460
    },
    {
      "epoch": 1.6095890410958904,
      "grad_norm": 0.002270711353048682,
      "learning_rate": 1.2179967254902693e-05,
      "loss": 0.0082,
      "step": 470
    },
    {
      "epoch": 1.643835616438356,
      "grad_norm": 0.07565478980541229,
      "learning_rate": 1.2046031520372747e-05,
      "loss": 0.0156,
      "step": 480
    },
    {
      "epoch": 1.678082191780822,
      "grad_norm": 0.00673523498699069,
      "learning_rate": 1.190976361319023e-05,
      "loss": 0.0163,
      "step": 490
    },
    {
      "epoch": 1.7123287671232876,
      "grad_norm": 0.36724594235420227,
      "learning_rate": 1.177123344054455e-05,
      "loss": 0.0092,
      "step": 500
    },
    {
      "epoch": 1.7465753424657535,
      "grad_norm": 0.9348287582397461,
      "learning_rate": 1.1630512070196405e-05,
      "loss": 0.0066,
      "step": 510
    },
    {
      "epoch": 1.7808219178082192,
      "grad_norm": 0.7213360667228699,
      "learning_rate": 1.1487671694019092e-05,
      "loss": 0.0161,
      "step": 520
    },
    {
      "epoch": 1.8150684931506849,
      "grad_norm": 0.47437942028045654,
      "learning_rate": 1.1342785590963178e-05,
      "loss": 0.0265,
      "step": 530
    },
    {
      "epoch": 1.8493150684931505,
      "grad_norm": 1.1204220056533813,
      "learning_rate": 1.1195928089463414e-05,
      "loss": 0.0141,
      "step": 540
    },
    {
      "epoch": 1.8835616438356164,
      "grad_norm": 0.27822205424308777,
      "learning_rate": 1.1047174529307332e-05,
      "loss": 0.011,
      "step": 550
    },
    {
      "epoch": 1.9178082191780823,
      "grad_norm": 0.25541847944259644,
      "learning_rate": 1.0896601222984931e-05,
      "loss": 0.0131,
      "step": 560
    },
    {
      "epoch": 1.952054794520548,
      "grad_norm": 0.02540596015751362,
      "learning_rate": 1.0744285416539418e-05,
      "loss": 0.0133,
      "step": 570
    },
    {
      "epoch": 1.9863013698630136,
      "grad_norm": 0.010820313356816769,
      "learning_rate": 1.0590305249938968e-05,
      "loss": 0.0107,
      "step": 580
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.01489537674933672,
      "eval_runtime": 33.9982,
      "eval_samples_per_second": 3.765,
      "eval_steps_per_second": 0.471,
      "step": 584
    },
    {
      "epoch": 2.0205479452054793,
      "grad_norm": 0.01333385705947876,
      "learning_rate": 1.0434739716989936e-05,
      "loss": 0.001,
      "step": 590
    },
    {
      "epoch": 2.0547945205479454,
      "grad_norm": 0.05179058760404587,
      "learning_rate": 1.0277668624811998e-05,
      "loss": 0.0024,
      "step": 600
    },
    {
      "epoch": 2.089041095890411,
      "grad_norm": 0.2092834860086441,
      "learning_rate": 1.0119172552896097e-05,
      "loss": 0.0039,
      "step": 610
    },
    {
      "epoch": 2.1232876712328768,
      "grad_norm": 0.022856567054986954,
      "learning_rate": 9.9593328117661e-06,
      "loss": 0.0021,
      "step": 620
    },
    {
      "epoch": 2.1575342465753424,
      "grad_norm": 0.014025694690644741,
      "learning_rate": 9.79823140126547e-06,
      "loss": 0.0027,
      "step": 630
    },
    {
      "epoch": 2.191780821917808,
      "grad_norm": 0.0005872066831216216,
      "learning_rate": 9.635950968490296e-06,
      "loss": 0.0081,
      "step": 640
    },
    {
      "epoch": 2.2260273972602738,
      "grad_norm": 1.1289536952972412,
      "learning_rate": 9.472574765390256e-06,
      "loss": 0.0027,
      "step": 650
    },
    {
      "epoch": 2.26027397260274,
      "grad_norm": 0.07355684787034988,
      "learning_rate": 9.308186606059292e-06,
      "loss": 0.0055,
      "step": 660
    },
    {
      "epoch": 2.2945205479452055,
      "grad_norm": 0.014707176946103573,
      "learning_rate": 9.142870823737927e-06,
      "loss": 0.0043,
      "step": 670
    },
    {
      "epoch": 2.328767123287671,
      "grad_norm": 0.0015542081091552973,
      "learning_rate": 8.976712227549202e-06,
      "loss": 0.0073,
      "step": 680
    },
    {
      "epoch": 2.363013698630137,
      "grad_norm": 0.0014431894524022937,
      "learning_rate": 8.809796058990516e-06,
      "loss": 0.0044,
      "step": 690
    },
    {
      "epoch": 2.3972602739726026,
      "grad_norm": 0.003427540184929967,
      "learning_rate": 8.642207948203637e-06,
      "loss": 0.0028,
      "step": 700
    },
    {
      "epoch": 2.4315068493150687,
      "grad_norm": 0.0010300565045326948,
      "learning_rate": 8.474033870045348e-06,
      "loss": 0.0007,
      "step": 710
    },
    {
      "epoch": 2.4657534246575343,
      "grad_norm": 0.0020586687605828047,
      "learning_rate": 8.305360099981224e-06,
      "loss": 0.0006,
      "step": 720
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.00010464031947776675,
      "learning_rate": 8.13627316982522e-06,
      "loss": 0.0059,
      "step": 730
    },
    {
      "epoch": 2.5342465753424657,
      "grad_norm": 0.011612270958721638,
      "learning_rate": 7.966859823347734e-06,
      "loss": 0.0003,
      "step": 740
    },
    {
      "epoch": 2.5684931506849313,
      "grad_norm": 0.5867435932159424,
      "learning_rate": 7.797206971774927e-06,
      "loss": 0.0047,
      "step": 750
    },
    {
      "epoch": 2.602739726027397,
      "grad_norm": 0.00012937220162712038,
      "learning_rate": 7.627401649202172e-06,
      "loss": 0.0019,
      "step": 760
    },
    {
      "epoch": 2.636986301369863,
      "grad_norm": 1.333022952079773,
      "learning_rate": 7.457530967944412e-06,
      "loss": 0.0073,
      "step": 770
    },
    {
      "epoch": 2.671232876712329,
      "grad_norm": 0.0013836094876751304,
      "learning_rate": 7.2876820738464385e-06,
      "loss": 0.0004,
      "step": 780
    },
    {
      "epoch": 2.7054794520547945,
      "grad_norm": 0.005539131350815296,
      "learning_rate": 7.117942101575957e-06,
      "loss": 0.0004,
      "step": 790
    },
    {
      "epoch": 2.73972602739726,
      "grad_norm": 0.002890615724027157,
      "learning_rate": 6.948398129922367e-06,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 2.7739726027397262,
      "grad_norm": 0.008106114342808723,
      "learning_rate": 6.779137137124233e-06,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 2.808219178082192,
      "grad_norm": 0.0035691543016582727,
      "learning_rate": 6.6102459562483264e-06,
      "loss": 0.0001,
      "step": 820
    },
    {
      "epoch": 2.8424657534246576,
      "grad_norm": 0.9179275631904602,
      "learning_rate": 6.441811230643143e-06,
      "loss": 0.0074,
      "step": 830
    },
    {
      "epoch": 2.8767123287671232,
      "grad_norm": 6.694779585814103e-05,
      "learning_rate": 6.273919369489755e-06,
      "loss": 0.0001,
      "step": 840
    },
    {
      "epoch": 2.910958904109589,
      "grad_norm": 1.0281049013137817,
      "learning_rate": 6.1066565034727865e-06,
      "loss": 0.0011,
      "step": 850
    },
    {
      "epoch": 2.9452054794520546,
      "grad_norm": 0.012829986400902271,
      "learning_rate": 5.940108440594264e-06,
      "loss": 0.0012,
      "step": 860
    },
    {
      "epoch": 2.9794520547945207,
      "grad_norm": 2.0616703033447266,
      "learning_rate": 5.7743606221530095e-06,
      "loss": 0.0077,
      "step": 870
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0322643406689167,
      "eval_runtime": 33.3581,
      "eval_samples_per_second": 3.837,
      "eval_steps_per_second": 0.48,
      "step": 876
    },
    {
      "epoch": 3.0136986301369864,
      "grad_norm": 0.0037495873402804136,
      "learning_rate": 5.609498078912152e-06,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 3.047945205479452,
      "grad_norm": 9.099110320676118e-05,
      "learning_rate": 5.445605387477258e-06,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 3.0821917808219177,
      "grad_norm": 0.0013533245073631406,
      "learning_rate": 5.282766626907437e-06,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 3.1164383561643834,
      "grad_norm": 0.029127854853868484,
      "learning_rate": 5.121065335581706e-06,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 3.1506849315068495,
      "grad_norm": 0.00014029988960828632,
      "learning_rate": 4.96058446834273e-06,
      "loss": 0.0003,
      "step": 920
    },
    {
      "epoch": 3.184931506849315,
      "grad_norm": 0.0006689340225420892,
      "learning_rate": 4.801406353939917e-06,
      "loss": 0.0,
      "step": 930
    },
    {
      "epoch": 3.219178082191781,
      "grad_norm": 0.0013057825854048133,
      "learning_rate": 4.643612652793705e-06,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 3.2534246575342465,
      "grad_norm": 0.006577842868864536,
      "learning_rate": 4.487284315102731e-06,
      "loss": 0.0,
      "step": 950
    },
    {
      "epoch": 3.287671232876712,
      "grad_norm": 0.0012410003691911697,
      "learning_rate": 4.332501539315318e-06,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 3.3219178082191783,
      "grad_norm": 0.012426987290382385,
      "learning_rate": 4.179343730986662e-06,
      "loss": 0.0058,
      "step": 970
    },
    {
      "epoch": 3.356164383561644,
      "grad_norm": 6.759559619240463e-05,
      "learning_rate": 4.027889462042733e-06,
      "loss": 0.0009,
      "step": 980
    },
    {
      "epoch": 3.3904109589041096,
      "grad_norm": 0.00032462039962410927,
      "learning_rate": 3.878216430471892e-06,
      "loss": 0.0,
      "step": 990
    },
    {
      "epoch": 3.4246575342465753,
      "grad_norm": 0.0004913684679195285,
      "learning_rate": 3.7304014204648114e-06,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 3.458904109589041,
      "grad_norm": 6.198763730935752e-05,
      "learning_rate": 3.5845202630231995e-06,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 3.493150684931507,
      "grad_norm": 0.000963532947935164,
      "learning_rate": 3.4406477970575116e-06,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 3.5273972602739727,
      "grad_norm": 0.0002827442076522857,
      "learning_rate": 3.2988578309936463e-06,
      "loss": 0.0,
      "step": 1030
    },
    {
      "epoch": 3.5616438356164384,
      "grad_norm": 0.0003337405505590141,
      "learning_rate": 3.15922310490826e-06,
      "loss": 0.0042,
      "step": 1040
    },
    {
      "epoch": 3.595890410958904,
      "grad_norm": 5.2431205403991044e-05,
      "learning_rate": 3.021815253212166e-06,
      "loss": 0.0,
      "step": 1050
    },
    {
      "epoch": 3.6301369863013697,
      "grad_norm": 0.057092998176813126,
      "learning_rate": 2.886704767900975e-06,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 3.6643835616438354,
      "grad_norm": 0.0008765971870161593,
      "learning_rate": 2.75396096239179e-06,
      "loss": 0.0,
      "step": 1070
    },
    {
      "epoch": 3.6986301369863015,
      "grad_norm": 0.006450328044593334,
      "learning_rate": 2.6236519359645196e-06,
      "loss": 0.0001,
      "step": 1080
    },
    {
      "epoch": 3.732876712328767,
      "grad_norm": 0.003969810903072357,
      "learning_rate": 2.4958445388260916e-06,
      "loss": 0.0045,
      "step": 1090
    },
    {
      "epoch": 3.767123287671233,
      "grad_norm": 0.0024826503358781338,
      "learning_rate": 2.370604337815423e-06,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 3.8013698630136985,
      "grad_norm": 0.007169035263359547,
      "learning_rate": 2.2479955827667857e-06,
      "loss": 0.0044,
      "step": 1110
    },
    {
      "epoch": 3.8356164383561646,
      "grad_norm": 0.0014315959997475147,
      "learning_rate": 2.1280811735488263e-06,
      "loss": 0.0022,
      "step": 1120
    },
    {
      "epoch": 3.8698630136986303,
      "grad_norm": 0.0023928002920001745,
      "learning_rate": 2.0109226277961205e-06,
      "loss": 0.0,
      "step": 1130
    },
    {
      "epoch": 3.904109589041096,
      "grad_norm": 0.001930374070070684,
      "learning_rate": 1.8965800493498307e-06,
      "loss": 0.0066,
      "step": 1140
    },
    {
      "epoch": 3.9383561643835616,
      "grad_norm": 0.00020114821381866932,
      "learning_rate": 1.785112097423661e-06,
      "loss": 0.0007,
      "step": 1150
    },
    {
      "epoch": 3.9726027397260273,
      "grad_norm": 0.004381604492664337,
      "learning_rate": 1.6765759565109362e-06,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.036911629140377045,
      "eval_runtime": 33.4454,
      "eval_samples_per_second": 3.827,
      "eval_steps_per_second": 0.478,
      "step": 1168
    }
  ],
  "logging_steps": 10,
  "max_steps": 1460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.1047855730723226e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
